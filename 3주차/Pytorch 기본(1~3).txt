○ Intorduction to Pytorch

- 딥러닝은 프레임워크를 사용해야 한다.
  → 대표적으로 Pytorch, TensorFlow

- Keras vs TF vs Pytorch
  (user ↔ Keras wrapper → TF, Pytorch)

- Pytorch - Dynamic Computational Graph
  (Define by run; 실행을 하면서 그래프를 생성하는 방식)
  TensorFlow - Define and run 
  (그래프를 먼저 정의 후 실행시점에 데이터를 feed)

  → (Pytorch의 경우) 코드가 훨씬 간결해 진다.

      Why Pytorch
  → 즉시 확인 가능 - pythonic code
  → GPU support, Good API ana Community
  → 사용하기 편한 장점이 가장 큼
  → TF는 production과 scalability의 장점

 
- Pytorch - Numpy + Autograd + Function
   → Numpy 구조를 가지는 Tensor 객체로 array표현
   → 자동미분을 지원하여 DL연산을 지원
   → 다양한 형태의 DL을 지원하는 함수와 모델을 지원함


○ Pytorch Basics
Pytorch Operations (numpy + AutoGrad)

- Tensor
  → 다차원 Arrays를 표현하는 Pytorch 클래스
  → numpy의 ndarray와 동일
  → Tensor를 생성하는 함수도 거의 동일

  → 생성 : t_array = torch.FloatTensor(n_array)
  → 형태 확인 : t_array.ndim , t_array.shape
  → Array to Tensor - Tensor 생성은 list나 ndarray를 사용가능
     (torch.tensor(data_list), torch.from_numpy(nd_array_ex))
  → Tensor가 가질수 있는 데이터 타입은 Numpy와 동일
  → numpy like operations
  → pytorch의 tensor는 GPU에 올려서 사용가능
     (x_data.device #device(type='cpu')  / 
      if torch.cuda.is_available(): x_data_cuda = x_data.to('cuda')
      x_data_cuda.device)


- Tensor handling
  → view, squeeze, unsqueeze 등으로 tensor 조정가능
     view : reshape과 동일하게 tensor의 shape을 변환
     (reshape과는 contiguity 보장의 차이)
     squeeze : 차원의 개수가 1인 차원을 삭제
     unsqueeze : 차원의 개수가 1인 차원을 추가

- Tensor operations
  → tensor의 operations는 numpy와 동일
  → 행렬곱셈 연산은 dot이 아닌 mm 사용
     (dot : 벡터 곱셈 / mm : 행렬 곱셈 / matmul : 행렬 곱셈 & 브로드캐스팅)

- Tensor operations for ML/DL formula
  → nn.functional 모듈을 통해 다양한 수식 변환을 지원함
      (ie. F.softmax(), F.functional.one_hot()...)


- AutoGrad
  → Pytorch의 핵심은 자동 미분의 지원 - backward 함수 사용




○ Pytorch project Template Overview

- 대화식 개발과정인 주피터는 공유/배포에서 단점을 가진다.
  → OOP + 모듈화를 통한 프로젝트 단위로 개발하여
     개발 용이성 확보와 유지보수 향상이 필요
     (즉, 프로젝트로 개발하자!)
  → 이 때 프로젝트 템플릿을 이용하면 표준화된 방식으로 개발할 수 있다.
     (템플릿 - 프로젝트를 다양한 모듈로 분리한 것)


- Module 구성
  실행, 설정, base - abstract module, data, model-architecture, loss, metric
  저장소 - 로그, 모델 상태, 학습 수행, 로깅설정, 유틸리티


- ngrok
  colab과 같은 곳에 원격으로 접속하도록 지원하는 도구
  
  → ((ngrok 사이트)) 로그인 - Setup&Installation - 2. authtoken 내용 복사
     - ((이를 colab))에서 NGROK_TOKEN값으로 지정 / PASSWORD값 지정
     - !pip install colab-ssh
     - from_ssh import launch_ssh
       launch_ssh(NGROK_TOKEN, PASSWORD) 
     - 실행 결과(HostName, Port)를 가지고 내 컴퓨터와 연결작업을 한다.
       ※ (ssh로 내 컴퓨터에 접근할 수 있는) ngrok의 서버가 로드된다.
     -  ((내 컴퓨터 VScode))에서 Remote-SSH 설치
     - ctrl + shift + P - Remote-SSH: Add New 선택
     - ssh root@HostName값 -p Port값 - 해당 정보 저장 장소 선택
     - ctrl + shift + P - Remote-SSH: Connect to Host - Continue - Password입력
  → Terminal에 들어가면(cd.. / ls) colab에 접근된 것을 확인할 수 있다.
     (* 프로젝트를 불러오면 해당 에디터에서 작업이 가능하다.)



- config.json / parse_config.py / util.py
  → config.json - 설정 내용이 json형태로 담긴 파일
  → parse_config.py - factory pattern으로된 파일로 input 값을 넣어주면 객체를 생성해주는 곳이다.
  → util.py - read_json메서드를 포함하는 파일로 해당 메서드는 json 파일을 읽어와 하나의 dict파일로 만들어준다.
  → * tain.py에서 사용되는 것을 참고하자.

  → 설정값을 바꿔줌으로써 데이터나 모델 등을 모듈처럼 갈아끼워 넣을 수 있다.



- train.py / trainer.py (base_tainer.py - train메서드) / saved
  → train.py - trainer에 model, data 등의 정보를 넘겨준고 실행한다.
  → trainer.py - 받은 정보를 바탕으로 학습을 하는 곳
  → saved파일 - train.py - _save_checkpoint메서드에서 학습결과를 중간마다 saved파일에 저장해준다.


